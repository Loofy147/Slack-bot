"""
Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
"""
import os
import json
import logging
from openai import OpenAI
from jinja2 import Environment, FileSystemLoader
import argparse
from datetime import datetime
from dotenv import load_dotenv
import time
from system_integrator import SystemIntegrator
from config import Config

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_orchestrator.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class EnhancedOrchestrator:
    """Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø­Ø³Ù† Ù…Ø¹ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
    
    def __init__(self):
        self.config = Config()
        self.system_integrator = SystemIntegrator(self.config)
        self.client = OpenAI(api_key=self.config.OPENAI_API_KEY)
        
        # Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ù…Ø¹ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„
        self.phases = [
            ('Phase 0', 'Ideation', True),
            ('Phase 1', 'Research', True),
            ('Phase 2', 'Design', True),
            ('Phase 3', 'Development Plan', True),
            ('Phase 4', 'Execution', True),  # Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
            ('Phase 5', 'Review & Optimize', True),
            ('Phase 6', 'Deploy & Integrate', True)  # Ù…Ø±Ø­Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ù†Ø´Ø± ÙˆØ§Ù„ØªÙƒØ§Ù…Ù„
        ]
    
    def call_model_with_integration(self, prompt: str, enable_integration: bool = False, max_retries: int = 3):
        """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
        
        # Ø¥Ø¶Ø§ÙØ© ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        if enable_integration:
            integration_prompt = self._get_integration_prompt()
            prompt = f"{prompt}\n\n{integration_prompt}"
        
        for attempt in range(max_retries):
            try:
                # Ù‚Ø±Ø§Ø¡Ø© system prompt Ø§Ù„Ù…Ø­Ø³Ù†
                with open('prompts/enhanced_system_prompt.md', 'r', encoding='utf-8') as f:
                    system_content = f.read()
                
                response = self.client.chat.completions.create(
                    model=self.config.OPENAI_MODEL,
                    messages=[
                        {'role': 'system', 'content': system_content},
                        {'role': 'user', 'content': prompt}
                    ],
                    max_tokens=self.config.OPENAI_MAX_TOKENS,
                    temperature=self.config.OPENAI_TEMPERATURE
                )
                
                response_content = response.choices[0].message.content
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙØ¹Ù„Ø©
                if enable_integration:
                    response_content = self._process_integration_requests(response_content)
                
                return response_content
                
            except Exception as e:
                logger.warning(f"Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1} ÙØ´Ù„Øª: {e}")
                if attempt < max_retries - 1:
                    wait_time = (2 ** attempt) + 1
                    logger.info(f"Ø§Ù†ØªØ¸Ø§Ø± {wait_time} Ø«Ø§Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©...")
                    time.sleep(wait_time)
                if attempt == max_retries - 1:
                    logger.error(f"ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ {max_retries} Ù…Ø­Ø§ÙˆÙ„Ø§Øª")
                    return f"Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. {str(e)}"
    
    def _get_integration_prompt(self) -> str:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
        return """
## Ù‚Ø¯Ø±Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ø§Ù„Ù…ØªØ§Ø­Ø©:

ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø·Ù„Ø¨ ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªØ§Ù„ÙŠ:

```json
{
  "integration_request": {
    "type": "Ù†ÙˆØ¹_Ø§Ù„Ø¹Ù…Ù„ÙŠØ©",
    "parameters": {
      "Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª": "Ø§Ù„Ù‚ÙŠÙ…"
    }
  }
}
```

### Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:

1. **file_system**: Ø¥Ù†Ø´Ø§Ø¡ØŒ ØªØ¹Ø¯ÙŠÙ„ØŒ Ø­Ø°Ù Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
2. **git_operations**: Ø¹Ù…Ù„ÙŠØ§Øª Git (commit, push, branch)
3. **package_management**: ØªØ«Ø¨ÙŠØª ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø²Ù…
4. **database_operations**: Ø¹Ù…Ù„ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
5. **api_calls**: Ø§Ø³ØªØ¯Ø¹Ø§Ø¡Ø§Øª API Ø®Ø§Ø±Ø¬ÙŠØ©
6. **deployment**: Ù†Ø´Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
7. **system_commands**: ØªÙ†ÙÙŠØ° Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù†Ø¸Ø§Ù…
8. **environment_variables**: Ø¥Ø¯Ø§Ø±Ø© Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©

### Ø£Ù…Ø«Ù„Ø©:

```json
{
  "integration_request": {
    "type": "file_system",
    "parameters": {
      "operation": "create_file",
      "path": "new_feature.py",
      "content": "# ÙƒÙˆØ¯ Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©"
    }
  }
}
```

```json
{
  "integration_request": {
    "type": "package_management",
    "parameters": {
      "operation": "install",
      "package": "requests"
    }
  }
}
```

Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø¹Ù†Ø¯Ù…Ø§ ØªØ­ØªØ§Ø¬ Ù„ØªÙ†ÙÙŠØ° ØªØºÙŠÙŠØ±Ø§Øª ÙØ¹Ù„ÙŠØ© ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù….
"""
    
    def _process_integration_requests(self, response_content: str) -> str:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©"""
        lines = response_content.split('\n')
        processed_lines = []
        integration_results = []
        
        i = 0
        while i < len(lines):
            line = lines[i]
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø·Ù„Ø¨Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„
            if '```json' in line and i + 1 < len(lines):
                json_content = ""
                i += 1
                
                # Ø¬Ù…Ø¹ Ù…Ø­ØªÙˆÙ‰ JSON
                while i < len(lines) and '```' not in lines[i]:
                    json_content += lines[i] + '\n'
                    i += 1
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Ø§Ù„ØªÙƒØ§Ù…Ù„
                try:
                    request_data = json.loads(json_content.strip())
                    if 'integration_request' in request_data:
                        result = self._execute_integration_request(request_data['integration_request'])
                        integration_results.append(result)
                        
                        # Ø¥Ø¶Ø§ÙØ© Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªÙ†ÙÙŠØ° Ù„Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                        processed_lines.append(f"âœ… **ØªÙ… ØªÙ†ÙÙŠØ° Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:** {result['message'] if result['success'] else result['error']}")
                    else:
                        processed_lines.append('```json')
                        processed_lines.append(json_content.strip())
                        processed_lines.append('```')
                except json.JSONDecodeError:
                    processed_lines.append('```json')
                    processed_lines.append(json_content.strip())
                    processed_lines.append('```')
                except Exception as e:
                    processed_lines.append(f"âŒ **Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†ÙÙŠØ°:** {str(e)}")
            else:
                processed_lines.append(line)
            
            i += 1
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©
        if integration_results:
            processed_lines.append("\n## Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©:")
            for i, result in enumerate(integration_results, 1):
                status = "âœ…" if result['success'] else "âŒ"
                processed_lines.append(f"{i}. {status} {result.get('message', result.get('error', 'Ø¹Ù…Ù„ÙŠØ© ØºÙŠØ± Ù…Ø­Ø¯Ø¯Ø©'))}")
        
        return '\n'.join(processed_lines)
    
    def _execute_integration_request(self, request: dict) -> dict:
        """ØªÙ†ÙÙŠØ° Ø·Ù„Ø¨ Ø§Ù„ØªÙƒØ§Ù…Ù„"""
        request_type = request.get('type')
        parameters = request.get('parameters', {})
        
        logger.info(f"ØªÙ†ÙÙŠØ° Ø·Ù„Ø¨ ØªÙƒØ§Ù…Ù„: {request_type}")
        
        return self.system_integrator.execute_ai_request(request_type, parameters)
    
    def process_topic_enhanced(self, topic: str, enable_integration: bool = False):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ÙˆØ¶ÙˆØ¹ Ù…Ø¹ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø­Ø³Ù†"""
        logger.info(f"Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹: {topic}")
        
        try:
            user_template = self._load_template('user_prompt_template.md')
            base_prompt = user_template.render(topic=topic)
            logger.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ù†Ø¬Ø§Ø­")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {e}")
            return None

        outputs = {
            'metadata': {
                'topic': topic,
                'timestamp': datetime.now().isoformat(),
                'total_phases': len(self.phases),
                'integration_enabled': enable_integration
            },
            'phases': {},
            'integration_log': []
        }
        
        successful_phases = 0
        
        for phase_code, phase_name, integration_allowed in self.phases:
            logger.info(f"Ù…Ø¹Ø§Ù„Ø¬Ø© {phase_code}: {phase_name}")
            
            try:
                task_tpl = self._load_template('task_prompt.md')
                prompt_text = task_tpl.render(
                    phase_name=f'{phase_code}: {phase_name}',
                    task_name='Main Task',
                    context=topic,
                    task_description=f'Define the main goals and requirements for {phase_name} given the topic: {topic}'
                )
                
                # ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù…Ø³Ù…ÙˆØ­Ø©
                phase_integration = enable_integration and integration_allowed
                
                result = self.call_model_with_integration(prompt_text, phase_integration)
                
                outputs['phases'][phase_code] = {
                    'phase': phase_name,
                    'prompt': prompt_text,
                    'response': result,
                    'status': 'success',
                    'integration_enabled': phase_integration,
                    'timestamp': datetime.now().isoformat()
                }
                
                successful_phases += 1
                logger.info(f"ØªÙ… Ø¥Ù†Ø¬Ø§Ø² {phase_code} Ø¨Ù†Ø¬Ø§Ø­")
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© {phase_code}: {e}")
                outputs['phases'][phase_code] = {
                    'phase': phase_name,
                    'error': str(e),
                    'status': 'failed',
                    'timestamp': datetime.now().isoformat()
                }
        
        outputs['metadata']['successful_phases'] = successful_phases
        outputs['metadata']['success_rate'] = f"{(successful_phases/len(self.phases)*100):.1f}%"
        
        # Ø¥Ø¶Ø§ÙØ© Ø³Ø¬Ù„ Ø§Ù„ØªÙƒØ§Ù…Ù„
        outputs['integration_log'] = self.system_integrator.get_execution_history()
        
        return outputs
    
    def _load_template(self, name):
        """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ù„Ø¨ Ù…Ù† Ù…Ø¬Ù„Ø¯ prompts"""
        try:
            env = Environment(loader=FileSystemLoader('prompts'))
            return env.get_template(name)
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù„Ø¨ {name}: {e}")
            raise

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Enhanced AI Orchestrator with direct system integration')
    parser.add_argument('--input', required=True, help='Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹')
    parser.add_argument('--output', default='examples/enhanced_run.json', help='Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬')
    parser.add_argument('--enable-integration', action='store_true', help='ØªÙØ¹ÙŠÙ„ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±')
    parser.add_argument('--verbose', '-v', action='store_true', help='ØªÙØ¹ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ù…ÙØµÙ„')
    args = parser.parse_args()

    # ØªØ¹Ø¯ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ø·Ù„Ø¨
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ examples Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    os.makedirs('examples', exist_ok=True)

    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ø³Ù†
    orchestrator = EnhancedOrchestrator()
    
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
    results = orchestrator.process_topic_enhanced(args.input, args.enable_integration)
    
    if results:
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {args.output}")
        print(f"\nâœ… ØªÙ… Ø¥Ù†Ø¬Ø§Ø² Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© Ø¨Ù†Ø¬Ø§Ø­!")
        print(f"ğŸ“Š Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {results['metadata']['success_rate']}")
        print(f"ğŸ“ˆ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {results['metadata']['successful_phases']}/{results['metadata']['total_phases']}")
        print(f"ğŸ”§ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±: {'Ù…ÙØ¹Ù„' if args.enable_integration else 'Ù…Ø¹Ø·Ù„'}")
        print(f"ğŸ“ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ: {args.output}")
        
        # Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØ¹Ù„Ø§Ù‹
        if args.enable_integration and results['integration_log']:
            print(f"\nğŸ”— Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ù†ÙØ°Ø©: {len(results['integration_log'])}")
            for i, log_entry in enumerate(results['integration_log'], 1):
                status = "âœ…" if log_entry['result']['success'] else "âŒ"
                print(f"  {i}. {status} {log_entry['request_type']}")
    else:
        logger.error("ÙØ´Ù„ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹")
        exit(1)